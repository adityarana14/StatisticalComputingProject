<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>autoElasticRegression</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">autoElasticRegression</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(simpleEnsembleGroup09)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;glmnet&quot;</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>    <span class="co"># If not, install glmnet</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>    <span class="fu">install.packages</span>(<span class="st">&quot;glmnet&quot;</span>)</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>    <span class="fu">message</span>(<span class="st">&quot;The &#39;glmnet&#39; package was not installed. It has been installed now.&quot;</span>)</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>  }</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>  <span class="fu">library</span>(glmnet)</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co">#&gt; Loading required package: Matrix</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co">#&gt; Loaded glmnet 4.1-8</span></span></code></pre></div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The <code>autoElasticRegression</code> function fits an Elastic Net
regression model to a given dataset, with optional bagging to improve
model robustness and reduce variance. Elastic Net combines Lasso (L1
regularization) and Ridge (L2 regularization), offering a flexible
approach to feature selection and regularization. This vignette
demonstrates how to use the function with bagging, and explains how to
combine results from multiple bagged models for stable and robust
outcomes.</p>
</div>
<div id="function-overview" class="section level2">
<h2>Function Overview</h2>
<p>The <code>autoElasticRegression</code> function can fit Elastic Net
regression with or without bagging. Bagging (Bootstrap Aggregating)
creates multiple bootstrapped samples, fits separate models to each, and
averages their results to reduce variance. This vignette shows how to
use the function and explains the benefits of bagging in this
context.</p>
</div>
<div id="parameters" class="section level2">
<h2>Parameters</h2>
<ul>
<li><strong>X</strong>: A data frame or matrix containing the predictor
variables.</li>
<li><strong>y</strong>: A vector representing the response variable,
which can be binary or continuous.</li>
<li><strong>lambda</strong>: The regularization parameter for Elastic
Net. If <code>NULL</code>, it will be calculated using
cross-validation.</li>
<li><strong>alpha</strong>: The mixing parameter for Elastic Net,
ranging from 0 (Ridge) to 1 (Lasso). If <code>NULL</code>, it’s
determined using cross-validation.</li>
<li><strong>family</strong>: The type of response variable. Can be
<code>&quot;binary&quot;</code> for logistic regression or <code>&quot;gaussian&quot;</code>
for linear regression.</li>
<li><strong>bagging</strong>: Logical indicating whether to use bagging
(default is <code>FALSE</code>).</li>
<li><strong>n_bags</strong>: The number of bootstrapped samples for
bagging (default is <code>50</code>).</li>
</ul>
</div>
<div id="handling-missing-data" class="section level2">
<h2>Handling Missing Data</h2>
<p>The function checks for missing data in <code>X</code> and
<code>y</code>. If any missing values are found, the corresponding rows
are removed to ensure a clean dataset for model fitting.</p>
</div>
<div id="bagging-process" class="section level2">
<h2>Bagging Process</h2>
<p>If bagging = TRUE, the function creates n_bags bootstrapped samples
by randomly selecting rows with replacement from the original dataset.
It fits an Elastic Net regression model to each sample, allowing you to
calculate the standard deviations of coefficients and derive importance
scores for predictors.</p>
<p>If bagging = TRUE, the function creates multiple bootstrapped samples
and fits a lasso regression model to each. This process allows you to
assess the variability of coefficients across models and derive
importance scores to identify which predictors are consistently
selected.</p>
<p><strong>Bootstrapped Samples:</strong> Given a dataset with n
observations, a bootstrapped sample is created by selecting n
observations with replacement. This process allows some observations to
be selected multiple times, while others might not be selected at
all.</p>
<p><strong>Fitting Models:</strong> Once you have a set of bootstrapped
samples, a model (in this case, lasso regression) is fitted to each
sample. Because each sample is different due to random sampling, the
resulting models can vary, reflecting different perspectives on the
underlying data.</p>
<p><strong>Combining Results:</strong> After fitting models to multiple
bootstrapped samples, the results are combined to create a more robust
output. This combining process is central to bagging, where the goal is
to reduce variance by leveraging the diversity of the bootstrapped
samples.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">100</span> <span class="sc">*</span> <span class="dv">4</span>), <span class="at">ncol =</span> <span class="dv">4</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>, <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co"># Running the function without bagging</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">autoElasticRegression</span>(X, y)</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co">#&gt; Family auto-detected as:  binary</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co">#&gt; Warning in autoElasticRegression(X, y): No &#39;alpha&#39; provided. Using</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="co">#&gt; cross-validation to determine optimal alpha.</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co">#&gt; Optimal alpha used: 0.6</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co">#&gt; Warning in autoElasticRegression(X, y): No &#39;lambda&#39; provided. Using</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="co">#&gt; cross-validation to determine optimal lambda.</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="co">#&gt; Optimal lambda used: 0.1099286</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="co"># Running the function with bagging to improve estimates</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>result_bagged <span class="ot">&lt;-</span> <span class="fu">autoElasticRegression</span>(X, y, <span class="at">bagging =</span> <span class="cn">TRUE</span>, <span class="at">n_bags =</span> <span class="dv">50</span>)</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a><span class="co">#&gt; Family auto-detected as:  binary</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a><span class="co">#&gt; Warning in autoElasticRegression(X, y, bagging = TRUE, n_bags = 50): No &#39;alpha&#39;</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a><span class="co">#&gt; provided. Using cross-validation to determine optimal alpha.</span></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a><span class="co">#&gt; Optimal alpha used: 1</span></span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a><span class="co">#&gt; Warning in autoElasticRegression(X, y, bagging = TRUE, n_bags = 50): No</span></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a><span class="co">#&gt; &#39;lambda&#39; provided. Using cross-validation to determine optimal lambda.</span></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a><span class="co">#&gt; Optimal lambda used: 0.06595715 </span></span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a><span class="co">#&gt; Bagging complete. Averaged predictions from 50 models.</span></span></code></pre></div>
</div>
<div id="combining-results-from-bagged-models" class="section level2">
<h2>Combining Results from Bagged Models</h2>
<p>When bagging is enabled, autoElasticRegression creates n_bags
bootstrapped samples, fitting an Elastic Net regression model to each.
The results are combined to create final predictions and importance
scores.</p>
<p><strong>Averaging Predictions:</strong> Final predictions are derived
by averaging the predictions from all bagged models. This approach
reduces individual model variance, providing more stable outcomes.
<strong>Importance Scores:</strong> Importance scores are calculated by
counting how many times each predictor is selected with a non-zero
coefficient across all bagged models. This gives insights into which
predictors are most consistently contributing to the model’s
outcome.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co"># Use the function with bagging</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># Example with 50 bootstrapped samples</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>result_with_bagging <span class="ot">&lt;-</span> <span class="fu">autoElasticRegression</span>(<span class="at">y =</span> y, <span class="at">X =</span> X,  <span class="at">bagging =</span> <span class="cn">TRUE</span>, <span class="at">n_bags =</span> <span class="dv">50</span>)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co">#&gt; Family auto-detected as:  binary</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co">#&gt; Warning in autoElasticRegression(y = y, X = X, bagging = TRUE, n_bags = 50): No</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co">#&gt; &#39;alpha&#39; provided. Using cross-validation to determine optimal alpha.</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co">#&gt; Optimal alpha used: 0.8</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co">#&gt; Warning in autoElasticRegression(y = y, X = X, bagging = TRUE, n_bags = 50): No</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="co">#&gt; &#39;lambda&#39; provided. Using cross-validation to determine optimal lambda.</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co">#&gt; Optimal lambda used: 0.04717888 </span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co">#&gt; Bagging complete. Averaged predictions from 50 models.</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="co"># Display final predictions from all bagged models</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Final predictions from bagged models:&quot;</span>)</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Final predictions from bagged models:&quot;</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">head</span>(result_with_bagging<span class="sc">$</span>predictions))<span class="co"># Print first 5 predictions</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="co">#&gt; [1] 0.4312300 0.4698295 0.4484381 0.4603628 0.4208708 0.4069756</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="co"># Display importance scores</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Importance scores for predictors:&quot;</span>) <span class="co"># Print importance scores</span></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Importance scores for predictors:&quot;</span></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a><span class="fu">print</span>(result_with_bagging<span class="sc">$</span>importance_scores)</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a><span class="co">#&gt; [1] 23 38 26 32</span></span></code></pre></div>
</div>
<div id="final-thoughts" class="section level2">
<h2>Final Thoughts</h2>
<p>The autoElasticRegression function provides a flexible approach to
Elastic Net regression with optional bagging. This vignette has shown
how to use the function, interpret its results, and understand the
benefits of bagging in providing robust model outputs. By examining the
importance scores and final predictions, you can gain insights into
which predictors are most significant and how bagging contributes to
model stability and robustness.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>

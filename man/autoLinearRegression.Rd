% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LinearReg.R
\name{autoLinearRegression}
\alias{autoLinearRegression}
\title{Auto Linear Regression Model with Optional Bagging}
\usage{
autoLinearRegression(X, y, bagging = FALSE, B = 100)
}
\arguments{
\item{X}{A matrix of predictors.}

\item{y}{A vector representing the response variable, which can be binary or continuous.}

\item{bagging}{A logical indicating whether bagging should be used.
Defaults to FALSE.}

\item{B}{An integer specifying the number of bootstrap samples to use if bagging is TRUE.
Defaults to 100.}
}
\value{
A list containing the following components:
        \itemize{
          \item{lm}{The fitted lm model object.}
          \item{coefficients}{A matrix containing estimates, standard errors, z-values, and p-values for each coefficient.}
          \item{fitted.values}{The fitted values using the fitted model.}
}
}
\description{
The autoLinearRegression function automates linear regression modeling on a given dataset X
and response variable y. It checks for binary responses and suggests logistic regression if
applicable. The function handles scenarios where the number of predictors exceeds the number
of observations by selecting the most significant predictors. It then estimates coefficients
using ordinary least squares regression (lm). If the bagging option is enabled, it performs
bagging by repeatedly sampling with replacement, calculates standard errors, z-values, and p-values
for each coefficient. The function returns a summary including the linear model object,
coefficients, and fitted values, offering a streamlined approach to linear regression analysis.
}
\examples{
\dontrun{
  # Generate synthetic data
  set.seed(123)
  n <- 100
  p <- 5
  X <- matrix(rnorm(n * p), n, p)
  y <- 1 + X[,1] - 2 * X[,2] + rnorm(n)
  colnames(X) <- paste0("Var", 1:ncol(X))

  # Use the function without bagging
  result_without_bagging <- autoLinearRegression(X = X, y = y)
  print(result_without_bagging$lm)

  # Use the function with bagging
  result_with_bagging <- autoLinearRegression(X = X, y = y, bagging = TRUE, B = 50)
  print(head(result_with_bagging$fitted.values))  # Print first 5 fitted values
  print(result_with_bagging$coefficients)  # Print coefficients
}


\dontrun{
  set.seed(42)  # For reproducibility
  # Number of samples
  num_samples <- 100

  # Create continuous predictors
  continuous_predictors <- data.frame(
    Age = rnorm(num_samples, mean = 30, sd = 10),  # Normally distributed
    Salary = rnorm(num_samples, mean = 50000, sd = 15000),  # Normally distributed
    Height = rnorm(num_samples, mean = 170, sd = 10)  # Normally distributed
  )

  # Create discrete predictors
  discrete_predictors <- data.frame(
    Children = rpois(num_samples, lambda = 2),  # Poisson distribution
    Siblings = sample(0:5, num_samples, replace = TRUE)  # Random integers
  )

  # Create binary predictors
  binary_predictors <- data.frame(
    OwnsCar = rbinom(num_samples, 1, 0.5),  # 0 or 1 with equal probability
    Gender = factor(sample(c("Male", "Female"), num_samples, replace = TRUE)),  # Factor with two levels
    Married = sample(c("Yes", "No"), num_samples, replace = TRUE)  # Factor with two levels
  )

  # Combine all predictors into one data frame
  mixed_data <- cbind(continuous_predictors, discrete_predictors, binary_predictors)

  # Check the first few rows of the dataset
  head(mixed_data)
  dim(mixed_data)

  mixed_data$Response_Continuous <- 10000 + 100 * mixed_data$Salary + rnorm(nrow(mixed_data), mean = 0, sd = 5000)
  mixed_data$Response_Binary <- ifelse(mixed_data$Age > 30, 1, 0)

  b=mixed_data[,-ncol(mixed_data)]
  v=mixed_data$Response_Binary
  res = autoLinearRegression(mixed_data, mixed_data$Response_Continuous, bagging = TRUE)
}
}
